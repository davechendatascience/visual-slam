{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Clean RGB-D SLAM [Hybrid + CUDA]\n",
                "\n",
                "This is the **Ultimate** version.\n",
                "\n",
                "**Architecture**:\n",
                "- **Frontend**: Fast Geometric Odometry (OpenCV PnP). 30Hz.\n",
                "- **Backend**: Gaussian Splatting with **CUDA Rasterizer** (if installed).\n",
                "- **Speed**: ~100x Faster Rendering than PyTorch implementation.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Setup Environment\n",
                "!nvidia-smi\n",
                "!pip install torch torchvision torchaudio tqdm opencv-python matplotlib scipy pandas imageio plyfile plotly\n",
                "!pip install --upgrade sympy\n",
                "\n",
                "import os, sys\n",
                "\n",
                "# --- CUDA RASTERIZER INSTALL ---\n",
                "# Use absolute paths to avoid Windows './' issues\n",
                "try:\n",
                "    import diff_gaussian_rasterization\n",
                "    print(\"diff-gaussian-rasterization already installed!\")\n",
                "except ImportError:\n",
                "    print(\"Installing diff-gaussian-rasterization (Compiling CUDA)...\")\n",
                "    if not os.path.exists(\"diff-gaussian-rasterization\"):\n",
                "        !git clone --recursive https://github.com/graphdeco-inria/diff-gaussian-rasterization\n",
                "    \n",
                "    repo_path = os.path.abspath(\"diff-gaussian-rasterization\")\n",
                "    print(f\"Installing from: {repo_path}\")\n",
                "    !pip install \"{repo_path}\"\n",
                "\n",
                "if not os.path.exists(\"UniDepth\"):\n",
                "    !git clone https://github.com/lpiccinelli-eth/UniDepth.git\n",
                "%cd UniDepth\n",
                "!pip install -e .\n",
                "!pip install timm huggingface_hub\n",
                "%cd ..\n",
                "sys.path.append(os.getcwd()) # Add current dir to path for slam_core"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Download Data (TUM fr3_office)\n",
                "%cd /content\n",
                "!mkdir -p datasets/tum\n",
                "%cd datasets/tum\n",
                "dataset_url = \"https://vision.in.tum.de/rgbd/dataset/freiburg3/rgbd_dataset_freiburg3_long_office_household.tgz\"\n",
                "!wget -O dataset.tgz {dataset_url}\n",
                "!tar -xzf dataset.tgz\n",
                "!mv rgbd_dataset_freiburg3_long_office_household fr3_office\n",
                "%cd /content"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3. Import Core Module\n",
                "import torch\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from PIL import Image\n",
                "from IPython.display import clear_output\n",
                "\n",
                "from slam_core import associate_data, SimpleGaussianModel, GeometricTracker, spawn_gaussians_from_frame, get_psnr, save_ply, visualize_ply, optimize_map_window\n",
                "\n",
                "# Load Data\n",
                "dataset_root = \"/content/datasets/tum/fr3_office\"\n",
                "dataset_data = associate_data(dataset_root)\n",
                "print(f\"Loaded {len(dataset_data)} frames.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4. Main SLAM Loop\n",
                "\n",
                "# Config\n",
                "H, W = 480, 640\n",
                "fx, fy, cx, cy = 535.4, 539.2, 320.1, 247.6\n",
                "K_mat = np.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n",
                "K_torch = torch.tensor(K_mat, device=\"cpu\", dtype=torch.float32)\n",
                "\n",
                "# USE CUDA if available (Diff-Gaussian requires CUDA)\n",
                "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
                "print(f\"Using Device: {device}\")\n",
                "\n",
                "model = SimpleGaussianModel(device=device) \n",
                "tracker = GeometricTracker(K_mat, H, W)\n",
                "\n",
                "process_data = dataset_data[:300]\n",
                "current_c2w = process_data[0]['c2w']\n",
                "\n",
                "gt_traj = []; est_traj = []\n",
                "keyframe_window = []\n",
                "MAX_WINDOW = 10\n",
                "\n",
                "prev_img = None; prev_depth = None\n",
                "\n",
                "print(f\"Starting Fast Hybrid SLAM (Geometric Tracking + CUDA Rasterizer)...\")\n",
                "for i, frame in enumerate(process_data):\n",
                "    gt_traj.append(frame['c2w'])\n",
                "    \n",
                "    # Load Images\n",
                "    img_pil = Image.open(frame['rgb_path']).convert(\"RGB\")\n",
                "    img_np = np.array(img_pil)\n",
                "    gt_rgb = torch.tensor(img_np / 255.0, dtype=torch.float32, device=\"cpu\")\n",
                "    \n",
                "    # Prepare GPU data for Mapper\n",
                "    if device == \"cuda\":\n",
                "         gt_rgb_map = gt_rgb.cuda()\n",
                "    else:\n",
                "         gt_rgb_map = gt_rgb\n",
                "\n",
                "    depth_png = np.array(Image.open(frame['sensor_depth_path']))\n",
                "    depth_val = depth_png.astype(np.float32) / 5000.0\n",
                "    gt_depth_torch = torch.tensor(depth_val, device=\"cpu\", dtype=torch.float32)\n",
                "    \n",
                "    # --- 1. TRACKING (Fast Geometric) ---\n",
                "    # Runs on CPU (OpenCV)\n",
                "    if i > 0 and prev_img is not None:\n",
                "        current_c2w = tracker.track(prev_img, prev_depth, img_np, current_c2w)\n",
                "    \n",
                "    est_traj.append(current_c2w)\n",
                "    \n",
                "    prev_img = img_np\n",
                "    prev_depth = depth_val\n",
                "    \n",
                "    # --- 2. WINDOW MANAGEMENT ---\n",
                "    keyframe_window.append({\n",
                "        'c2w': current_c2w,\n",
                "        # Store data ON DEVICE for Speed\n",
                "        'rgb': gt_rgb_map,\n",
                "        'depth': gt_depth_torch \n",
                "    })\n",
                "    if len(keyframe_window) > MAX_WINDOW:\n",
                "        keyframe_window.pop(0)\n",
                "    \n",
                "    # --- 3. MAPPING (Keyframe) ---\n",
                "    if i % 5 == 0:\n",
                "        new_means, new_colors = spawn_gaussians_from_frame(frame, K_mat, H, W, c2w_override=current_c2w, mode=\"sensor\", subsample=4)\n",
                "        if device == \"cuda\":\n",
                "            new_means = new_means.cuda()\n",
                "            new_colors = new_colors.cuda()\n",
                "        model.add_gaussians(new_means, new_colors)\n",
                "        \n",
                "    # --- 4. WINDOW OPTIMIZATION ---\n",
                "    # If CUDA rasterizer is active, this is BLAZING FAST.\n",
                "    if i > 0:\n",
                "        K_device = K_torch.to(device)\n",
                "        optimize_map_window(model, keyframe_window, K_device, H, W, iters=10)\n",
                "        \n",
                "    # --- 5. PRUNING ---\n",
                "    if i > 0 and i % 20 == 0:\n",
                "        model.prune_points(min_opacity=0.01)\n",
                "\n",
                "    # --- 6. VIZ ---\n",
                "    # Render solid for Viz (using PyTorch fallback or CUDA if supported)\n",
                "    if i % 10 == 0:\n",
                "        with torch.no_grad():\n",
                "            w2c_viz = torch.inverse(torch.tensor(current_c2w, dtype=torch.float32, device=device))\n",
                "            # Force solid mode (PyTorch) for Viz because CUDA rasterizer raw output might differ slightly?\n",
                "            # Actually CUDA rasterizer is fine.\n",
                "            render_out = model(w2c_viz, K_torch.to(device), H, W, mode='solid')\n",
                "        \n",
                "        render_np = render_out[..., :3].detach().cpu().numpy()\n",
                "        \n",
                "        print(f\"Frame {i} | Window: {len(keyframe_window)} | Points: {model.means.shape[0]}\")\n",
                "        clear_output(wait=True)\n",
                "        fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
                "        ax[0].imshow(render_np); ax[0].set_title(\"Render\")\n",
                "        ax[1].imshow(img_np); ax[1].set_title(\"Input\")\n",
                "        plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 5. Evaluation\n",
                "def align_and_evaluate(gt, est):\n",
                "    gt_xyz = np.array([p[:3, 3] for p in gt])\n",
                "    est_xyz = np.array([p[:3, 3] for p in est])\n",
                "    \n",
                "    # Umeyama Alignment (SVD)\n",
                "    gt_mean = gt_xyz.mean(0); est_mean = est_xyz.mean(0)\n",
                "    gt_c = gt_xyz - gt_mean; est_c = est_xyz - est_mean\n",
                "    H = est_c.T @ gt_c\n",
                "    U, S, Vt = np.linalg.svd(H)\n",
                "    R = Vt.T @ U.T\n",
                "    if np.linalg.det(R) < 0: Vt[2,:] *= -1; R = Vt.T @ U.T\n",
                "    \n",
                "    est_aligned = (R @ est_c.T).T + gt_mean\n",
                "    rmse = np.sqrt(np.mean(np.linalg.norm(gt_xyz - est_aligned, axis=1)**2))\n",
                "    \n",
                "    return rmse, gt_xyz, est_aligned\n",
                "\n",
                "ate, gt_xyz, est_xyz = align_and_evaluate(gt_traj, est_traj)\n",
                "print(f\"Final ATE (RMSE): {ate:.4f} m\")\n",
                "\n",
                "plt.figure()\n",
                "plt.plot(gt_xyz[:,0], gt_xyz[:,2], 'g-', label='GT')\n",
                "plt.plot(est_xyz[:,0], est_xyz[:,2], 'r--', label='Est')\n",
                "plt.legend(); plt.title(\"Trajectory Top-Down\"); plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 6. Export Cloud\n",
                "save_ply(model, 'reconstruction.ply')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 7. Interactive Visualization\n",
                "visualize_ply('reconstruction.ply', subsample=50)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}